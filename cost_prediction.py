# -*- coding: utf-8 -*-
"""cost_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FH9WSFcllUaGv8pCzDiItfdtQ8o3-v5x

# Imports
"""

!pip install shap
!pip install catboost

import sys
!{sys.executable} -m pip install shap
!{sys.executable} -m pip install catboost
!{sys.executable} -m pip install xgboost
!{sys.executable} -m pip install seaborn

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
import shap
from sklearn.tree import DecisionTreeRegressor
from sklearn import metrics
from sklearn import preprocessing

from sklearn import tree
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn import linear_model
import scipy.stats as ss
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import itertools
from catboost import CatBoostRegressor
from catboost import CatBoostClassifier

"""# Load the data"""

df = 0
trainfile = ' https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD' # replace this with https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD

def load_data():
    global df
    global trainfile
    df = pd.read_csv(trainfile)
    df = df.sample(frac=1)
    print(df.shape)

    df.drop(columns = ["Discharge Year"], inplace = True)
    df.reset_index(inplace = True,drop=True)


    x = np.asarray(df['Total Costs'].values,dtype=int)
    df['Total Costs'] = x

    df['Length of Stay'] = np.where(df['Length of Stay'] == "120 +", "120", df['Length of Stay'])
    x = np.asarray(df['Length of Stay'].values,dtype=int)
    df['Length of Stay'] = x
    df = df[(df['Total Costs'] <= 200000) & (df['Total Costs'] > 0)]
    print(df.shape)

from google.colab import drive
import os
drive.mount('/content/drive')
base_path = '/content/drive/cost_prediction'
if not (os.path.exists(base_path)):
    os.mkdir(base_path)

path_2016_data = os.path.join(base_path, 'data_2016.csv')
path_2017_data = os.path.join(base_path, 'data_2017.csv')
path_2018_data = os.path.join(base_path, 'data_2018.csv')
path_2019_data = os.path.join(base_path, 'data_2019.csv')

if not (os.path.exists(path_2016_data)):
    !wget -O $path_2016_data https://health.data.ny.gov/api/views/gnzp-ekau/rows.csv?accessType=DOWNLOAD
if not (os.path.exists(path_2017_data)):
    !wget -O $path_2017_data https://health.data.ny.gov/api/views/22g3-z7e7/rows.csv?accessType=DOWNLOAD
if not (os.path.exists(path_2018_data)):
    !wget -O $path_2018_data https://health.data.ny.gov/api/views/yjgt-tq93/rows.csv?accessType=DOWNLOAD
if not (os.path.exists(path_2019_data)):
    !wget -O $path_2019_data https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD

"""# Distribution of data"""

load_data()

print(df.values)

kde = ss.gaussian_kde(df)
xx, yy = np.mgrid[-3:3:.01, -1:4:.01]
density = kde(np.c_[xx.flat, yy.flat].T).reshape(xx.shape)

f, ax = plt.subplots()
cset = ax.contourf(xx, yy, density, cmap="viridis")
f.colorbar(cset)

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df.iloc[:10000,:], x="APR Severity of Illness Code", y="Total Costs",
    fill=True, thresh=0, levels=100, cmap="viridis", cbar=True,
)
plt.xlim(0.5, 4.5)
# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df.iloc[:10000,:], x="APR DRG Code", y="Total Costs",
    fill=True, thresh=0, levels=100, cmap="viridis", cbar=True,
)

# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Length of Stay", y="Total Costs",
    fill=True, thresh=0, levels=100, cmap="viridis", cbar=True,
)

# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Total Costs", hue="APR Severity of Illness Code", palette="autumn", cbar=True,
)

fig = plt.gcf()

fig.set_size_inches(10, 8)


# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Total Costs", hue="Length of Stay", palette="seismic", cbar=True,
)

fig = plt.gcf()

fig.set_size_inches(10, 8)


# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Total Costs", hue="Length of Stay", palette="binary", cbar=True,
)

fig = plt.gcf()

fig.set_size_inches(10, 8)


# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Total Costs", hue="Length of Stay", palette="afmhot", cbar=True,
)

fig = plt.gcf()

fig.set_size_inches(10, 8)


# plt.xticks(rotation=45)

plt.show()

plt.rcParams.update({'font.size': 10})
sns.kdeplot(
data=df[df["Length of Stay"] <= 10].iloc[:10000,:], x="Total Costs", hue="Length of Stay", palette="autumn", cbar=True,
)

fig = plt.gcf()

fig.set_size_inches(10, 8)


# plt.xticks(rotation=45)

plt.show()



df.columns

df.dtypes

numerical_columns = set(["Total Charges", "Total Costs", "Emergency Department Indicator", "Length of Stay", "Birth Weight"])
all_columns = set(df.columns)
cat_columns = all_columns.difference(numerical_columns)

df["Birth Weight"] = pd.to_numeric(df["Birth Weight"], errors = "coerce")

for col in cat_columns:
    if df.dtypes[col]=='category':
        print(f"{col} is already an categorical")
    else:
        print(f"converted {col} to categorical")
        df[col] = df[col].astype("category")

df.dtypes

def get_correlation(col1, col2):

    if ((col1.name in cat_columns) and (col2.name in cat_columns)):
        return cramers_corrected_stat(col1, col2)
    elif ((col1.name not in cat_columns) and (col2.name not in cat_columns)):
        return col2.corr(col1, method="pearson")
    elif (col1.name in cat_columns):
        col1_ordinated = col1.cat.codes
        return col2.corr(col1_ordinated, method="pearson")
    else:
        col2_ordinated = col2.cat.codes
        return col1.corr(col2_ordinated, method="pearson")



def cramers_corrected_stat(col1, col2):
    """ calculate Cramers V statistic for categorial-categorial association.
    """
    confusion_matrix = pd.crosstab(col1, col2)
    chi2 = ss.chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.values.sum()
    phi2 = chi2/n

    r,k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))
    rcorr = r - ((r-1)**2)/(n-1)
    kcorr = k - ((k-1)**2)/(n-1)
    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))

all_columns = list(df.columns)
n = len(all_columns)
c = np.zeros((n, n))
for i in range(n):
    c[i][i] = 1
    for j in range(i):
        corr = get_correlation(df[all_columns[i]], df[all_columns[j]])
        c[i][j] = corr
        c[j][i] = corr

corr = pd.DataFrame(c, columns = all_columns, index=all_columns)
corr

hm = sns.heatmap(corr, xticklabels=True, yticklabels=True)

hm.set(title = "Correlation Matrix\n")


fig = plt.gcf()

fig.set_size_inches(13, 11)
plt.rcParams.update({'font.size': 10})


plt.show()

print(df)

print(df.isna()) #isna detect missing values false if value exists and true for value does not exists

print(df.isna().sum())

print(df.sum())

df.isna().sum()/df.shape[0]

sns.kdeplot(x=df["Length of Stay"], y=df["Total Costs"], fill=True, cbar = True)
plt.title("Density Plot")
plt.xlabel("Length of Stay")
plt.xlim(0, 30)
plt.ylabel("Total Cost")

x = np.linspace(0, 30, num=100)
lr = linear_model.LinearRegression()
lr.fit(df["Length of Stay"].to_numpy().reshape(-1, 1),df["Total Costs"].to_numpy())
y = lr.predict(x.reshape(-1, 1))
plt.plot(x, y, color="black", linewidth=3, label="Best Fit")
plt.legend(bbox_to_anchor=(1.9, 1))

plt.rcParams.update({'font.size': 12})
plt.show()

print(df["Payment Typology 2"].value_counts())

r = int(df.shape[0] / 10)
pdf = df.iloc[:r, :]



print(df)

print(pdf)

sns.pairplot(pdf, kind="hist", x_vars=["Length of Stay"], y_vars =["Total Costs"], height=3)
x = np.linspace(0, 120, num=200)
lr = linear_model.LinearRegression()
lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
y = lr.predict(x.reshape(-1, 1))
plt.plot(x, y, color="blue", linewidth=1, label="Best Fit")
plt.legend(markerscale=5)
plt.figure(figsize = (80, 80))

plt.show()

g = sns.JointGrid(data=pdf, x="Length of Stay", y="Total Costs", marginal_ticks=True)
sns.kdeplot()
g.plot_joint(sns.kdeplot,  fill=True, cbar = True)

plt.title("Density Plot")
plt.xlabel("Length of Stay")
plt.xlim(0, 30)
plt.ylabel("Total Cost")

x = np.linspace(0, 30, num=100)
lr = linear_model.LinearRegression()
lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
y = lr.predict(x.reshape(-1, 1))

g.plot_joint(sns.lineplot, data=pd.DataFrame({"Length of Stay": x, "Total Costs": y}), x="x", y="y", fill=True, cbar = True)

plt.legend(bbox_to_anchor=(1.9, 1))


# Add the joint and marginal histogram plots

g.plot_marginals(sns.histplot, element="step")

"""# Cleaning the data for outliers and replotting"""

print(pdf.shape[0])
pdf = pdf[(pdf['Total Costs'] < 500000) & (pdf['Total Costs'] > 0)]
print(pdf.shape[0])

sns.pairplot(pdf, kind="scatter", x_vars=["Length of Stay"], y_vars =["Total Costs"], height = 3, plot_kws={"s": 5})
x = np.linspace(0, 120, num=200)
lr = linear_model.LinearRegression()
lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
y = lr.predict(x.reshape(-1, 1))
plt.plot(x, y, color="blue", linewidth=3, label="Best Fit")
plt.legend(bbox_to_anchor=(1.9, 1))


plt.show()

sns.pairplot(pdf[pdf["Total Costs"] < 100000], kind="kde", x_vars=["Length of Stay"], y_vars =["Total Costs"])
x = np.linspace(0, 20, num=200)
lr = linear_model.LinearRegression()
lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
y = lr.predict(x.reshape(-1, 1))
plt.plot(x, y, color="blue", linewidth=3, label="Best Fit")
plt.legend(bbox_to_anchor=(1.9, 1))


plt.show()

sns.histplot(pdf, x = "Total Costs")

sns.kdeplot(pdf, x = "Total Costs")

pdf = df.iloc[:, :]
uniq_vals = pdf["APR DRG Code"].unique()
print(f"Number of Distinct DRG Codes: {uniq_vals.shape[0]}")

print(pdf.shape)

for val in uniq_vals:
    r_df = df[df["APR DRG Code"] == val]
    if (r_df.shape[0] < 5000):
        continue
    plt.figure()
    sns.pairplot(r_df, kind="hist", x_vars=["Length of Stay"], y_vars =["Total Costs"])
    x = np.linspace(0, 120, num=200)
    lr = linear_model.LinearRegression()
    lr.fit(r_df["Length of Stay"].to_numpy().reshape(-1, 1), r_df["Total Costs"].to_numpy())
    y = lr.predict(x.reshape(-1, 1))
    plt.plot(x, y, color="blue", linewidth=3, label="Best Fit")
    plt.legend(bbox_to_anchor=(1.9, 1))
    plt.title(f"Distribution for APR DRG Code {val}")
    print(f"saved {val}")

    plt.savefig(f'DRG Code {val}.png', bbox_inches='tight')
    plt.close()

"""# Not using any target encoding"""



load_data()
original_df = df.copy()

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )
df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)
original_df = df.copy()

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

df.columns

categorical_columns = ['Hospital Service Area', 'Hospital County',
       'Operating Certificate Number', 'Permanent Facility Id',
       'Facility Name', 'Age Group', 'Zip Code - 3 digits', 'Gender', 'Race',
       'Ethnicity',  'Type of Admission',
       'Patient Disposition', 'CCSR Diagnosis Code', 'CCSR Procedure Code',
       'APR DRG Code', 'APR MDC Code', 'APR Severity of Illness Code',
       'APR Risk of Mortality', 'APR Medical Surgical Description',
       'Payment Typology 1', 'Birth Weight', 'Emergency Department Indicator',]

for col in categorical_columns:
    df[col] = df[col].astype('str')

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

clf = CatBoostRegressor(verbose=False, cat_features=categorical_columns)
clf.fit(Xtrain,Ytrain)
r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")



cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using CatBoost regressor {cv_score}")

"""# Using All features except total charges"""

load_data()
original_df = df.copy()

V = df["Type of Admission"].value_counts() / df["Type of Admission"].shape[0]
print(V)

df.dtypes

df["APR DRG Code"][df["APR DRG Description"]=="HIP JOINT REPLACEMENT"]

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )
df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)
original_df = df.copy()

df.shape

columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator', 'Patient Disposition', "Age Group",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR DRG Code","APR MDC Code",
                            "Facility Name"]

numeric_columns = ['Total Costs']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns)
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)
            mean_los = np.mean(Xtrain["Length of Stay"].loc[Xtrain[col]==val].values)
            target_encoding_dict[col][val] = mean_cost / (mean_los + 1e-6)
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col]) * df["Length of Stay"]

df

Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]


Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

clf = RandomForestRegressor(max_depth=10,n_estimators=20)
clf.fit(Xtrain,Ytrain)

r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using random forest regressor {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using Random Forests", xlabel="Error")
k = ss.kurtosis(error)
rms = np.sqrt(np.mean(error.values**2))
print(f"rms = {rms}")
print(f"Kurtosis = {k}")

plt.xlim(-50000, 50000)
plt.show()

clf = CatBoostRegressor(verbose=False)
clf.fit(Xtrain,Ytrain)
r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using CatBoost regressor {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using CatBoost Regressor", xlabel="Error")

k = ss.kurtosis(error)
print(f"Kurtosis = {k}")

rms = np.sqrt(np.mean(error.values**2))
print(f"rms = {rms}")
plt.xlim(-50000, 50000)
plt.show()

Ypred = clf.predict(Xtest)

sns.kdeplot(x=Ytest, y=Ypred, fill=True, cbar = True)
m, b = np.polyfit(Ytest,Ypred,1)
plt.plot(Ytest,m*Ytest+b,"k")
plt.plot(Ytest,Ytest,"r")
plt.legend(['Best Fit Line','Exact Line'])
plt.title("Scatterplot for Predicted vs Actual Total Costs")
plt.xlabel("Actual Total Cost")
plt.ylabel("Predicted Total Cost")
plt.rcParams.update({'font.size': 12})
plt.xlim(0, 55000)
plt.ylim(0, 55000)
plt.show()

df

pdf = df[original_df["APR DRG Code"] == 301.0]
print(pdf.shape)
X = pdf.iloc[:, :-1]
Y = pdf.iloc[:, -1]
Ypredict = clf.predict(X)
print(np.median(Y))
print(np.median(Ypredict))

df.columns

error

clf = DecisionTreeRegressor(max_depth=10)
clf.fit(Xtrain,Ytrain)


r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using Single Decision Tree {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using Decision Tree", xlabel="Error")

k = ss.kurtosis(error)
print(f"Kurtosis = {k}")
rms = np.sqrt(np.mean(error.values**2))
print(f"rms = {rms}")

plt.xlim(-50000, 50000)
plt.show()

clf = DecisionTreeRegressor(max_depth=5)
clf.fit(Xtrain,Ytrain)

from sklearn.tree import export_graphviz
dot_data = export_graphviz(clf, out_file=None, max_depth = 2,
                feature_names = Xtrain.columns, rotate=True,
                rounded = True, proportion = False,
                precision = 2, filled = True)

import graphviz

graph = graphviz.Source(dot_data, format="png")
graph.save("single decision tree classifier.dot")

!dot -Tjpeg "single decision tree classifier.dot" -o "single decision tree classifier.jpeg"

shap_values = shap.TreeExplainer(clf)(Xtest)
shap.summary_plot(shap_values, Xtest)

shap.plots.scatter(shap_values[:,"APR Severity of Illness Code_"])

import matplotlib.pyplot as plt
import numpy as np


plt.rcdefaults()
fig, ax = plt.subplots()

# Example data
features = Xtrain.columns
y_pos = np.arange(len(features))



ax.barh(y_pos, clf.feature_importances_, align='center')
ax.set_yticks(y_pos)
ax.set_yticklabels(Xtrain.columns)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Feature importance')
ax.set_title('Feature importance using a Random Forest Regressor')

plt.show()

"""# Naive Regressor"""

load_data()

df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )

"""## Getting feature contributions"""

def get_feature_contributions(X, Y):
    contributions = {}
    for column in X.columns:
        unique_values = X[column].unique()
        contributions[column] = {}

        for unique_val in unique_values:
            contributions[column][unique_val] = Y[X[column]==unique_val].mean()
    return contributions

def predict_using_feature_contributions(X, contributions, chosen_columns):
    Y = np.zeros(X.shape[0])
    chosen_columns = [X.columns[i] for i in chosen_columns]
    for column in X.columns:
        if column in chosen_columns:
            Y += X[column].map(contributions[column]).fillna(0)


    return Y / len(chosen_columns)

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

feature_contributions = get_feature_contributions(Xtrain, Ytrain)

"""## Predicting LoS using the feature contributions"""

n = len(df.columns) - 1
all_combinations = list(itertools.combinations(list(range(n)), 2))

all_combinations += list(itertools.combinations(list(range(n)), 3))
all_combinations += list(itertools.combinations(list(range(n)), 4))

all_combinations += list(itertools.combinations(list(range(n)), n))

len(all_combinations)

max_r2 = -1
max_cb = None
for combination in all_combinations:

    prediction = predict_using_feature_contributions(Xtest, feature_contributions, combination)
    combination_in_strings = [df.columns[i] for i in combination]
    r2_sc = r2_score(Ytest.values, prediction)
    if r2_sc > max_r2:
        max_cb = combination
    max_r2 = max(max_r2, r2_sc)

    print(f"R2 score = {r2_sc}, using columns = {combination}")

max_r2, max_cb

[df.columns[i] for i in max_cb]

X = df.iloc[:, :-1]
Y = df.iloc[:, -1]

folds = 10
kf = KFold(n_splits=folds)
fold = 1
final_score = 0
for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
    feature_contributions = get_feature_contributions(X_train, y_train )
    prediction = predict_using_feature_contributions(X_test, feature_contributions, max_cb)

    score = r2_score(y_test.values, prediction)
    print(f"In fold {fold}: r2 score = {score}")
    final_score += score
    fold += 1
final_score /= folds
print(f"{folds}-fold cv score - {final_score}")

"""# Target encoding"""

load_data()

df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])

print(df.columns)

columns_to_target_encode = ['Hospital Service Area', 'Hospital County',
       'Operating Certificate Number', 'Permanent Facility Id',
       'Facility Name', 'Age Group', 'Zip Code - 3 digits', 'Gender', 'Race',
       'Ethnicity', 'Length of Stay', 'Type of Admission',
       'Patient Disposition', 'CCSR Diagnosis Code', 'CCSR Procedure Code',
       'APR DRG Code', 'APR MDC Code', 'APR Severity of Illness Code',
       'APR Risk of Mortality', 'APR Medical Surgical Description',
       'Payment Typology 1', 'Emergency Department Indicator',
       ]

numeric_columns = ['Total Costs', 'Birth Weight']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns)
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
          mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)
          mean_los = np.mean(Xtrain["Length of Stay"].loc[Xtrain[col]==val].values)

          target_encoding_dict[col][val] = mean_cost / mean_los

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
    df[col] = df[col] * (1 + df["Length of Stay"])

Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

clf = RandomForestRegressor(max_depth=10,n_estimators=20)
clf.fit(Xtrain,Ytrain)

Ypred = clf.predict(Xtest)
r2 = metrics.r2_score(Ytest, Ypred)
print(f"r2 score = {r2}")

clf = RandomForestRegressor(max_depth=10, n_estimators=20)
cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using random forest regressor {cv_score}")

clf = CatBoostRegressor()
clf.fit(Xtrain,Ytrain)

Ypred = clf.predict(Xtest)
r2 = metrics.r2_score(Ytest, Ypred)
print(f"r2 score = {r2}")
mape = metrics.mean_absolute_percentage_error(Ytest, Ypred)
print(f"mean absolute percentage error score = {mape}")

clf = CatBoostRegressor(verbose = False)
cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using catboost regressor {cv_score}")

clf = DecisionTreeRegressor(max_depth=10)
clf.fit(Xtrain,Ytrain)

Ypred = clf.predict(Xtest)
r2 = metrics.r2_score(Ytest, Ypred)
print(f"r2 score = {r2}")

clf = DecisionTreeRegressor(max_depth=10)
cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using decision tree regressor {cv_score}")

shap.initjs()

explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(Xtest)
shap.force_plot(explainer.expected_value, shap_values[1,:], Xtest.iloc[1,:])

explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(Xtest.iloc[1:500, :])
shap.force_plot(explainer.expected_value, shap_values[1:500,:], Xtest.iloc[1:500,:])

shap.summary_plot(shap_values[1:500, :], Xtest.iloc[1:500, :], axis_color = "blue", color_bar = False, title = "Shap")

"""# All features except total charges, LOS, and Patient Disposition

# New section
"""

load_data()

df.dtypes

df.drop(['Length of Stay', 'Patient Disposition', 'CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description', 'APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )

columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator',  "Age Group", "APR Severity of Illness Code",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR DRG Code","APR MDC Code",
                            "Facility Name"]

numeric_columns = ['Total Costs']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns)
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)

            target_encoding_dict[col][val] = mean_cost
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])

df

df.iloc[0, :]

Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

clf = RandomForestRegressor(max_depth=10,n_estimators=20)
clf.fit(Xtrain,Ytrain)
r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using random forest regressor {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using Random Forest Regressor", xlabel="Error")
k = ss.kurtosis(error)
print(f"Kurtosis = {k}")
rms = np.sqrt(np.mean(error**2))
print(f"RMS = {rms}")
plt.xlim(-50000, 50000)

plt.show()

clf = CatBoostRegressor(verbose=False)
clf.fit(Xtrain,Ytrain)


r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

error = clf.predict(Xtest) - Ytest
k = ss.kurtosis(error)
print(f"Kurtosis = {k}")

rms = np.sqrt(np.mean(error**2))
print(f"RMS = {rms}")
sns.histplot(data=error).set(title="Error histogram using CatBoost Regressor", xlabel="Error")
plt.xlim(-50000, 50000)
plt.show()

clf = CatBoostRegressor(verbose=False)
cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using CatBoost regressor {cv_score}")

clf = DecisionTreeRegressor(max_depth=10)
clf.fit(Xtrain,Ytrain)


r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using Single Decision Tree {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using a single Decision Tree (max depth = 10)", xlabel="Error")

rms = np.sqrt(np.mean(error**2))
print(f"RMS = {rms}")
k = ss.kurtosis(error)
print(f"Kurtosis = {k}")
plt.xlim(-50000, 50000)
plt.show()

shap_values = shap.TreeExplainer(clf).shap_values(Xtest)
shap.summary_plot(shap_values, Xtest)

import matplotlib.pyplot as plt
import numpy as np


plt.rcdefaults()
fig, ax = plt.subplots()

# Example data
features = Xtrain.columns
y_pos = np.arange(len(features))



ax.barh(y_pos, clf.feature_importances_, align='center')
ax.set_yticks(y_pos)
ax.set_yticklabels(Xtrain.columns)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Feature importance')
ax.set_title('Feature importance using a Random Forest Regressor')

plt.show()

""" # DRG Codes"""

load_data()

df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )
columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator', 'Patient Disposition', "Age Group", "APR Severity of Illness Code",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR MDC Code",
                            "Facility Name"]

numeric_columns = ['Total Costs']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns).difference(set(["APR DRG Description"]))
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)


r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)


target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)
            mean_los = np.mean(Xtrain["Length of Stay"].loc[Xtrain[col]==val].values)
            target_encoding_dict[col][val] = mean_cost / (mean_los + 1e-6)
        else:
            target_encoding_dict[col][val] = 0




for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
    df[col] = df[col] * (1 + df["Length of Stay"])

drg_values = df["APR DRG Description"].value_counts()
print(drg_values)

drg_results = []

for actual_drg in drg_values.keys()[drg_values > 10000].values:


    partial_df = df[df["APR DRG Description"] == actual_drg]
    frac = partial_df.shape[0] / df.shape[0]

    r = int(partial_df.shape[0] * 0.1)
    Ytest = partial_df.iloc[0:r,-1]
    Xtest = partial_df.iloc[0:r,:-1].drop(columns=["APR DRG Description"])
    Ytrain = partial_df.iloc[r:,-1]
    Xtrain = partial_df.iloc[r:,:-1].drop(columns=["APR DRG Description"])

    clf = CatBoostRegressor(verbose = False)
    clf.fit(Xtrain,Ytrain)

    Ypred = clf.predict(Xtest)
    r2 = metrics.r2_score(Ytest, Ypred)

    drg_results.append([actual_drg, frac, r2])

sorted_drg = sorted(drg_results, key= lambda x: -x[2])

for drg in sorted_drg[:3]:
    pdf = df[df["APR DRG Description"] == drg[0]]
    sns.pairplot(pdf, kind="kde", x_vars=["Length of Stay"], y_vars =["Total Costs"], height = 3, plot_kws={"s": 5, "fill": True})
    x = np.linspace(0, 120, num=200)
    lr = linear_model.LinearRegression()
    lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
    y = lr.predict(x.reshape(-1, 1))
    plt.plot(x, y, color="blue", linewidth=3, label="Best Fit")
    plt.legend(bbox_to_anchor=(1.9, 1))
    plt.title(f"Cost vs Length of Stay for {drg[0]}")


    plt.show()

plt.rcParams.update({'font.size': 30})
df = pd.DataFrame(sorted_drg, columns=["APR DRG Description", "Fraction of dataset", "R2 score"])
df.iloc[:20, :].plot(y = "R2 score", x = "APR DRG Description", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(15, 13)

df = pd.DataFrame(sorted_drg, columns=["APR DRG Description", "Fraction of dataset", "R2 score"])
df.iloc[-20:, :].plot(y = "R2 score", x = "APR DRG Description", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(15, 13)
plt.rcParams.update({'font.size': 30})

df["Percentage of dataset"] = df["Fraction of dataset"] * 100
df.drop(columns=["Fraction of dataset"])
df.iloc[:30]

df.iloc[-30:]

""" # Facility Names"""

load_data()

df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )
columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator', 'Patient Disposition', "Age Group", "APR Severity of Illness Code",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR MDC Code",
                            "APR DRG Code"]

numeric_columns = ['Total Costs']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns).difference(set(["Facility Name"]))
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)


r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)


target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)
            mean_los = np.mean(Xtrain["Length of Stay"].loc[Xtrain[col]==val].values)
            target_encoding_dict[col][val] = mean_cost / (mean_los + 1e-6)
        else:
            target_encoding_dict[col][val] = 0




for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
    df[col] = df[col] * (1 + df["Length of Stay"])

drg_values = df["Facility Name"].value_counts()
print(drg_values)

drg_results = []

for actual_drg in drg_values.keys().values[:40]:


    partial_df = df[df["Facility Name"] == actual_drg]
    frac = partial_df.shape[0] / df.shape[0]
    # print(f" = {actual_drg}, fraction of total = {frac}")
    r = int(partial_df.shape[0] * 0.1)
    Ytest = partial_df.iloc[0:r,-1]
    Xtest = partial_df.iloc[0:r,:-1].drop(columns=["Facility Name"])
    Ytrain = partial_df.iloc[r:,-1]
    Xtrain = partial_df.iloc[r:,:-1].drop(columns=["Facility Name"])

    clf = CatBoostRegressor(verbose = False)
    clf.fit(Xtrain,Ytrain)

    Ypred = clf.predict(Xtest)
    r2 = metrics.r2_score(Ytest, Ypred)
    # print(f"r2 score = {r2}")


#     cv_score = np.mean((cross_val_score(clf, partial_df.iloc[1:, :-1], partial_df.iloc[1:, -1], cv=5)))
#     print(f"cross validation score using catboost regressor {cv_score}")
    drg_results.append([actual_drg, frac, r2])

print(drg_results)

sorted_drg = sorted(drg_results, key= lambda x: -x[2])

for drg in sorted_drg[:5]:
    pdf = df[df["Facility Name"] == drg[0]]
    sns.pairplot(pdf, kind="scatter", x_vars=["Length of Stay"], y_vars =["Total Costs"], height = 3, plot_kws={"s": 5})
    x = np.linspace(0, 120, num=200)
    lr = linear_model.LinearRegression()
    lr.fit(pdf["Length of Stay"].to_numpy().reshape(-1, 1), pdf["Total Costs"].to_numpy())
    y = lr.predict(x.reshape(-1, 1))
    plt.plot(x, y, color="blue", linewidth=3, label="Best Fit")
    plt.legend(bbox_to_anchor=(1.9, 1))
    plt.title(f"Total Costs versus Length of Stay where Facility Name is {drg[0]} and we get an r2 score of {drg[2]}")


    plt.show()

df = pd.DataFrame(sorted_drg, columns=["Facility Name", "Fraction of dataset", "R2 score"])
df.plot(y = "R2 score", x = "Facility Name", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(17, 15)
plt.rcParams.update({'font.size': 20})

df = pd.DataFrame(sorted_drg, columns=["Facility Name", "Fraction of dataset", "R2 score"])
df.iloc[:20, :].plot(y = "R2 score", x = "Facility Name", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(15, 13)
plt.rcParams.update({'font.size': 30})

df

"""# the 3d p"""

Xtrain = Xtrain.iloc[:r, :]
Ytrain = Ytrain.iloc[:r]

max_depths = [1, 3, 5, 7, 9, 11, 13, 15]
n_estimators = [1, 5, 9, 13, 17, 21, 25, 29]

max_depths = [1, 3, 5, 7, 9, 11, 13, 15]
n_estimators = [1, 5, 9, 13, 17, 21, 25, 29]

n_es = []
max_d = []
scores = []
for a in max_depths:
    for b in n_estimators:
        clf = RandomForestRegressor(max_depth=a,n_estimators=b)
        clf.fit(Xtrain,Ytrain)
        sc = clf.score(Xtest, Ytest)
        max_d.append(a)
        n_es.append(b)
        scores.append(max(sc, 0))

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.tri as mtri



fig = plt.figure(figsize=(30, 15))

x = max_d
y = n_es
z = scores

plt.rcParams.update({'font.size': 20})

triang = mtri.Triangulation(x, y)


ax = fig.add_subplot(1, 2, 2, projection='3d')
ax.plot_trisurf(triang, z, cmap=plt.cm.CMRmap)
ax.set_xlabel("number of estimators")
ax.set_ylabel("maximum depth")
plt.title("model r2 score using random forests")

plt.show()

sns.scatterplot(x=max_d, y=n_es, hue=z)

"""# Using percentiles"""

load_data()

# df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Cha rges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)
df.drop(['CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description','APR Severity of Illness Description', 'Total Charges', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df.sort_values("Total Costs", inplace=True, ignore_index=True)


df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )

total_size = df.shape[0]
df["Total Costs Percentile"] = 100.0 * df["Total Costs"].rank() / total_size

columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator', 'Patient Disposition', "Age Group", "APR Severity of Illness Code",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR DRG Code","APR MDC Code",
                            "Facility Name", 'Permanent Facility Id']

numeric_columns = ['Total Costs', 'Total Costs Percentile']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns)
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

r = df.shape[0]
r = int(r/10)

df = df.sample(frac=1)
df.drop(columns=["Total Costs"], inplace=True)

Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)
            mean_los = np.mean(Xtrain["Length of Stay"].loc[Xtrain[col]==val].values)
            target_encoding_dict[col][val] = mean_cost / (mean_los + 1e-6)
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col]) * df["Length of Stay"]

df.head()

Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

clf = RandomForestRegressor(max_depth=10,n_estimators=20)
clf.fit(Xtrain,Ytrain)
r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

Xtest.head()

Ytest.head()

Xtrain.head()

Ytrain.head()

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using random forest regressor {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using Random Forest Regressor (max depth = 10, number of estimators = 20)", xlabel="Error")

clf = CatBoostRegressor(verbose=False)
clf.fit(Xtrain,Ytrain)


r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using CatBoost regressor {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using CatBoost Regressor", xlabel="Error")

clf = DecisionTreeRegressor(max_depth=10)
clf.fit(Xtrain,Ytrain)


r2 = clf.score(Xtest, Ytest)
print(f"r2 score = {r2}")

cv_score = np.mean((cross_val_score(clf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using Single Decision Tree {cv_score}")

error = clf.predict(Xtest) - Ytest
sns.histplot(data=error).set(title="Error histogram using a single Decision Tree (max depth = 10)", xlabel="Error")

"""# Los without  Patient dispostion"""

load_data()

df.dtypes

df.drop(['Length of Stay', 'Patient Disposition', 'CCSR Diagnosis Description','CCSR Procedure Description','APR DRG Description','APR MDC Description', 'APR Severity of Illness Description', 'Total Charges','Total Costs', 'Payment Typology 2', 'Payment Typology 3'],axis=1,inplace=True)

df = df.dropna(subset=['Hospital County','Operating Certificate Number', 'Permanent Facility Id','Zip Code - 3 digits', 'APR Risk of Mortality'])
df['Birth Weight'] = (
    pd.to_numeric(df['Birth Weight'],
                  errors='coerce')
      .fillna(0)
    )

columns_to_target_encode = ["Operating Certificate Number", 'CCSR Procedure Code','CCSR Diagnosis Code','Type of Admission', 'APR Risk of Mortality',
                            'APR Medical Surgical Description','Emergency Department Indicator',  "Age Group", "APR Severity of Illness Code",
                            "Hospital County", "Payment Typology 1", "Zip Code - 3 digits","APR DRG Code","APR MDC Code",
                            "Facility Name"]

numeric_columns = ['Length of Stay']
remaining_columns = set(df.columns).difference(set(columns_to_target_encode)).difference(numeric_columns)
for col in remaining_columns:
    uniq_vals = df[col].unique()
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

r = df.shape[0]
r = int(r/10)



Ytest = df.iloc[0:r,-1]
Xtest = df.iloc[0:r,:-1]
Ytrain = df.iloc[r:,-1]
Xtrain = df.iloc[r:,:-1]

Xtest.reset_index(inplace = True,drop=True)
Ytest.reset_index(inplace = True,drop=True)
Xtrain.reset_index(inplace=True, drop=True)
Ytrain.reset_index(inplace=True, drop=True)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (Ytrain[Xtrain[col]==val].shape[0] != 0):

            mean_cost = np.mean(Ytrain.loc[Xtrain[col]==val].values)

            target_encoding_dict[col][val] = mean_cost
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])

